import SparkMD5 from 'spark-md5';
/**
 * è®¡ç®—æ–‡ä»¶çš„ MD5 å“ˆå¸Œå€¼
 * æ”¯æŒä¸¤ç§å®ç°æ–¹å¼ï¼š
 * 1. ä½¿ç”¨ spark-md5 åº“ï¼ˆæ¨èï¼Œæ€§èƒ½å¥½ï¼Œæ”¯æŒ MD5ï¼‰- ä¼˜å…ˆåœ¨ä¸»çº¿ç¨‹ä½¿ç”¨
 * 2. ä½¿ç”¨ Web Crypto APIï¼ˆåŸç”Ÿï¼Œä¸éœ€è¦é¢å¤–ä¾èµ–ï¼Œä½†åªæ”¯æŒ SHA-256ï¼‰
 *
 * @param file è¦è®¡ç®—å“ˆå¸Œçš„æ–‡ä»¶
 * @param chunkSize è¯»å–æ–‡ä»¶æ—¶çš„åˆ†å—å¤§å°ï¼Œé»˜è®¤ 2MB
 * @param onProgress è¿›åº¦å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰
 * @param useSparkMD5 æ˜¯å¦ä½¿ç”¨ spark-md5ï¼Œé»˜è®¤å°è¯•ä½¿ç”¨
 * @returns Promise<string> æ–‡ä»¶çš„å“ˆå¸Œå€¼ï¼ˆMD5 æˆ– SHA-256ï¼‰
 */
export const calculateFileHash = async (
  file: File,
  chunkSize: number = 2 * 1024 * 1024, // é»˜è®¤ 2MB
  onProgress?: (progress: number) => void,
  useSparkMD5: boolean = true
): Promise<string> => {
  console.log('ğŸš€ å¼€å§‹è®¡ç®—æ–‡ä»¶å“ˆå¸Œ:', file.name, file.size);

  return calculateFileHashWithSparkMD5(file, chunkSize, onProgress, SparkMD5);
};

/**
 * ä½¿ç”¨ spark-md5 åœ¨ä¸»çº¿ç¨‹è®¡ç®—æ–‡ä»¶å“ˆå¸Œï¼ˆæµå¼å¤„ç†ï¼‰
 * å‚è€ƒï¼šhttps://blog.csdn.net/wenmin1987/article/details/142974150
 *
 * @param file è¦è®¡ç®—å“ˆå¸Œçš„æ–‡ä»¶
 * @param chunkSize è¯»å–æ–‡ä»¶æ—¶çš„åˆ†å—å¤§å°
 * @param onProgress è¿›åº¦å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰
 * @param SparkMD5 spark-md5 åº“çš„å¼•ç”¨
 * @returns Promise<string> æ–‡ä»¶çš„ MD5 å“ˆå¸Œå€¼
 */
const calculateFileHashWithSparkMD5 = async (
  file: File,
  chunkSize: number,
  onProgress: ((progress: number) => void) | undefined,
  SparkMD5: any
): Promise<string> => {
  const totalChunks = Math.ceil(file.size / chunkSize);
  console.log(
    `ğŸ“¦ æ–‡ä»¶å°†åˆ†ä¸º ${totalChunks} ä¸ªåˆ†å—ï¼Œæ¯å— ${(chunkSize / 1024 / 1024).toFixed(2)}MB`
  );

  return new Promise((resolve, reject) => {
    // åˆ›å»º sparkMD5 å®ä¾‹
    const spark = new SparkMD5.ArrayBuffer();
    let processedChunks = 0;

    // é€’å½’å‡½æ•°ï¼Œé€ä¸ªå¤„ç†åˆ†å—
    function _read(i: number) {
      // å¦‚æœæ‰€æœ‰åˆ†å—éƒ½å·²å¤„ç†å®Œæ¯•
      if (i >= totalChunks) {
        // è®¡ç®—æœ€ç»ˆå“ˆå¸Œå€¼
        const hash = spark.end();
        console.log('âœ… æ–‡ä»¶å“ˆå¸Œè®¡ç®—å®Œæˆ:', hash);
        resolve(hash);
        return;
      }

      // è·å–å½“å‰åˆ†å—
      const start = i * chunkSize;
      const end = Math.min(start + chunkSize, file.size);
      const blob = file.slice(start, end);

      // åˆ›å»º FileReader è¯»å–åˆ†å—
      const reader = new FileReader();

      // è¯»å–å®Œæˆå›è°ƒ
      reader.onload = e => {
        try {
          // è·å–è¯»å–åˆ°çš„å­—èŠ‚æ•°ç»„
          const bytes = e.target?.result as ArrayBuffer;

          // å°†å­—èŠ‚æ•°ç»„æ·»åŠ åˆ° sparkMD5 å®ä¾‹ä¸­
          spark.append(bytes);
          processedChunks++;

          // æ›´æ–°è¿›åº¦
          if (onProgress) {
            const progress = Math.round((processedChunks / totalChunks) * 100);
            onProgress(progress);
          }

          // é€’å½’å¤„ç†ä¸‹ä¸€ä¸ªåˆ†å—
          _read(i + 1);
        } catch (error) {
          reject(new Error(`å¤„ç†åˆ†å—å¤±è´¥: ${error}`));
        }
      };

      // è¯»å–é”™è¯¯å›è°ƒ
      reader.onerror = () => {
        reject(new Error('æ–‡ä»¶è¯»å–å¤±è´¥'));
      };

      // ä»¥ ArrayBuffer æ ¼å¼å¼‚æ­¥è¯»å–å½“å‰åˆ†å—
      reader.readAsArrayBuffer(blob);
    }

    // ä»ç´¢å¼• 0 å¼€å§‹å¤„ç†
    _read(0);
  });
};
